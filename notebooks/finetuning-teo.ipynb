{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Returning secret from environment variable `HF_API_KEY`=`hf...Gk`\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/teo/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gpu_mem_used_MB': 4950.07,\n",
       " 'gpu_mem_free_MB': 1070.6,\n",
       " 'gpu_mem_total_MB': 6020.66}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append('../')\n",
    "\n",
    "from torch import nn, Tensor, save\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import src.utils as ut\n",
    "import src.trainer as trn\n",
    "import src.finetuning as ft\n",
    "\n",
    "from src.utils import LLAMA_MODEL_ID, login_to_hf_hub\n",
    "from src.txt_dataset import TokenizedTxtDataset\n",
    "\n",
    "\n",
    "login_to_hf_hub()\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(LLAMA_MODEL_ID)\n",
    "\n",
    "ut.gpu_mem_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before installing LoRA layers:  {'gpu_mem_used_MB': 2569.8, 'gpu_mem_free_MB': 3450.86, 'gpu_mem_total_MB': 6020.66}\n",
      "Parámetros sin LoRA: 167,772,160 || Parámetros con LoRA: 3,407,872  || Porcentaje de parámetros con LoRA: 1.99%\n",
      "after installing LoRA layers:  {'gpu_mem_used_MB': 3119.25, 'gpu_mem_free_MB': 2901.41, 'gpu_mem_total_MB': 6020.66}\n"
     ]
    }
   ],
   "source": [
    "model = ut.load_raw_model()\n",
    "print(\"before installing LoRA layers: \", ut.gpu_mem_info())\n",
    "\n",
    "ft.freeze_and_install_lora(model, lora_rank=16)\n",
    "print(\"after installing LoRA layers: \", ut.gpu_mem_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/Estatutos-Universidad-de-los-Andes-2020-ratificados-MEN-RQ.preprocessed.txt             :  51,028 bytes,    819 lines\n",
      "../data/reglamento-maestria-web-2024.preprocessed.txt                                           :  60,045 bytes,    838 lines\n",
      "concat_files_to_str: returning 113,571 characters, whole text at: tokenized_txt_dataset.concat.txt\n",
      "TokenizedTxtDs.__init__: len(all_text)=113,571\n",
      "n_toks_raw: 28428 start_idx: 284 end_idx: 28428\n",
      "n_toks_sampled:  28,144  input_ids length (padded):  28,160 block_size: 128 n_blocks: 220\n",
      "../data/Estatutos-Universidad-de-los-Andes-2020-ratificados-MEN-RQ.preprocessed.txt             :  51,028 bytes,    819 lines\n",
      "../data/reglamento-maestria-web-2024.preprocessed.txt                                           :  60,045 bytes,    838 lines\n",
      "concat_files_to_str: returning 113,571 characters, whole text at: tokenized_txt_dataset.concat.txt\n",
      "TokenizedTxtDs.__init__: len(all_text)=113,571\n",
      "n_toks_raw: 28428 start_idx: 0 end_idx: 284\n",
      "n_toks_sampled:     284  input_ids length (padded):     384 block_size: 128 n_blocks: 3\n",
      "len(ds): 440 max_stride_mult: 2\n",
      "DEVICE: cuda\n",
      "\n",
      "Initializing trainer: device: cuda - len(train_ds)=440, len(valid_ds)=6\n",
      "Entrenando por 70 pasos. 1 epochs\n",
      "Nota Importante:\n",
      "    El `Train Loss` que se reporta se calcula únicamente sobre los datos de los últimos 8 pasos de entrenamiento.\n",
      "    El `Valid Loss` es sobre *todos* los datos de validación\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step    5 - Train loss: 2.174                     (tokens/sec: 1435) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    5 -                    Valid loss: 3.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step   10 - Train loss: 2.056                     (tokens/sec: 1567) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   10 -                    Valid loss: 3.018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step   15 - Train loss: 1.928                     (tokens/sec: 1552) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   15 -                    Valid loss: 3.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step   20 - Train loss: 1.941                     (tokens/sec: 1549) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   20 -                    Valid loss: 3.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step   25 - Train loss: 1.891                     (tokens/sec: 1544) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   25 -                    Valid loss: 3.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step   30 - Train loss: 1.925                     (tokens/sec: 1547) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   30 -                    Valid loss: 3.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step   35 - Train loss: 1.893                     (tokens/sec: 1542) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   35 -                    Valid loss: 1.943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step   40 - Train loss: 1.797                     (tokens/sec: 1538) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   40 -                    Valid loss: 1.134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step   45 - Train loss: 1.818                     (tokens/sec: 1539) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   45 -                    Valid loss: 1.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step   50 - Train loss: 1.736                     (tokens/sec: 1534) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   50 -                    Valid loss: 1.043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step   55 - Train loss: 1.752                     (tokens/sec: 1535) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   55 -                    Valid loss: 0.995\n",
      "train_dl exhausted, resetting... epoch_cnt=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step   60 - Train loss: 1.445                     (tokens/sec: 1536) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   60 -                    Valid loss: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step   65 - Train loss: 1.401                     (tokens/sec: 1526) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   65 -                    Valid loss: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step   69 - Train loss: 1.426                     (tokens/sec: 1525) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   69 -                    Valid loss: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step   70 - Train loss: 1.361                     (tokens/sec: 1511) - estimating loss on 'validation' dataset: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   70 -                    Valid loss: 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): LoraLinear(\n",
       "            (linear_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          )\n",
       "          (k_proj): LoraLinear(\n",
       "            (linear_layer): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          )\n",
       "          (v_proj): LoraLinear(\n",
       "            (linear_layer): Linear(in_features=2048, out_features=512, bias=False)\n",
       "          )\n",
       "          (o_proj): LoraLinear(\n",
       "            (linear_layer): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          )\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_fpaths = [\n",
    "    Path(\"../data/Estatutos-Universidad-de-los-Andes-2020-ratificados-MEN-RQ.preprocessed.txt\"),\n",
    "    Path(\"../data/reglamento-maestria-web-2024.preprocessed.txt\")\n",
    "]\n",
    "\n",
    "# English versions:\n",
    "\n",
    "# text_fpaths = [\n",
    "#    Path(\"../data/Estatutos-Universidad-de-los-Andes-2020-ratificados-MEN-RQ.translated.txt\"),\n",
    "#    Path(\"../data/reglamento-maestria-web-2024.translated.txt\"),\n",
    "#]\n",
    "\n",
    "train_ds = TokenizedTxtDataset(text_fpaths,\n",
    "                block_size=128,\n",
    "                stride=64,\n",
    "                tokenizer=TOKENIZER,\n",
    "                start_pct=1.0,\n",
    "                end_pct=100.0\n",
    "            )\n",
    "\n",
    "valid_ds = TokenizedTxtDataset(text_fpaths,\n",
    "                block_size=128,\n",
    "                stride=64,\n",
    "                tokenizer=TOKENIZER,\n",
    "                start_pct=0.0,\n",
    "                end_pct=1.0\n",
    "            )\n",
    "\n",
    "print(\"len(ds):\", len(train_ds), \"max_stride_mult:\", train_ds.max_stride_mult)\n",
    "\n",
    "DEVICE = ut.module_device(model)\n",
    "print(f\"DEVICE: {DEVICE}\")\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "VALID_BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-4\n",
    "\n",
    "trainer = trn.Trainer(\n",
    "    train_ds=train_ds,\n",
    "    train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    valid_ds=valid_ds,\n",
    "    valid_batch_size=VALID_BATCH_SIZE,\n",
    "    lr=LEARNING_RATE,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "def pred_next_token_loss(model: nn.Module, batch: dict[str, Tensor]) -> Tensor:\n",
    "    return model(input_ids=batch['input_ids'],\n",
    "                 attention_mask=batch['attention_mask'],\n",
    "                 labels=batch['input_ids']).loss\n",
    "\n",
    "trainer.train(model,\n",
    "              loss_fun=pred_next_token_loss,\n",
    "              max_steps=70,\n",
    "              accum_grad_steps=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(model, \"r16-e70-spa-v1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-maia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
